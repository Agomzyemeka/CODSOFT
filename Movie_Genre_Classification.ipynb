{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asL5Yy2EWrhZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG37Y-xgV4-F"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\AGOMOH\\.pyenv\\pyenv-win\\versions\\3.7.9\\python.exe\n",
            "TensorFlow version: 2.11.0\n",
            "Num GPUs Available:  0\n",
            "Is CUDA available: False\n",
            "CUDA device count: 0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    print(\"TensorFlow version:\", tf.__version__)\n",
        "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "except ImportError as e:\n",
        "    print(\"Error importing TensorFlow:\", e)\n",
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "is_cuda_available = torch.cuda.is_available()\n",
        "print(\"Is CUDA available:\", is_cuda_available)\n",
        "\n",
        "# Get the number of CUDA devices\n",
        "cuda_device_count = torch.cuda.device_count()\n",
        "print(\"CUDA device count:\", cuda_device_count)\n",
        "\n",
        "if is_cuda_available:\n",
        "    for i in range(cuda_device_count):\n",
        "        print(f\"CUDA Device {i}: {torch.cuda.get_device_name(i)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txX-2fFTXIZk"
      },
      "source": [
        "Cell 1: Import necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "w-P4vSvHXN06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\AGOMOH\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\AGOMOH\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import os\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Ensure output images directory exists\n",
        "os.makedirs('images', exist_ok=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAtVEDiUXenX"
      },
      "source": [
        "Cell 2: Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f04ETiguXeLW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset with specified encoding\n",
        "def load_data(file_path, is_train=True, encoding='utf-8'):\n",
        "    data = []\n",
        "    with open(file_path, 'r', encoding=encoding) as file:\n",
        "        for line in file.readlines():\n",
        "            parts = line.strip().split(' ::: ')\n",
        "            if is_train:\n",
        "                data.append({'ID': parts[0], 'TITLE': parts[1], 'GENRE': parts[2], 'DESCRIPTION': parts[3]})\n",
        "            else:\n",
        "                data.append({'ID': parts[0], 'TITLE': parts[1], 'DESCRIPTION': parts[2]})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Specify the file paths\n",
        "train_data_path = os.path.join('dataset', 'Genre Classification Dataset', 'train_data.txt')\n",
        "test_data_path = os.path.join('dataset', 'Genre Classification Dataset', 'test_data.txt')\n",
        "test_solutions_path = os.path.join('dataset', 'Genre Classification Dataset', 'test_data_solution.txt')\n",
        "\n",
        "# Load the data with UTF-8 encoding\n",
        "train_data = load_data(train_data_path, is_train=True, encoding='utf-8')\n",
        "test_data = load_data(test_data_path, is_train=False, encoding='utf-8')\n",
        "test_solutions = pd.read_csv(test_solutions_path, sep=' ::: ', engine='python', header=None, names=['ID', 'GENRE'], encoding='utf-8')\n",
        "\n",
        "# If UTF-8 encoding doesn't work, try with 'latin-1'\n",
        "# train_data = load_data(train_data_path, is_train=True, encoding='latin-1')\n",
        "# test_data = load_data(test_data_path, is_train=False, encoding='latin-1')\n",
        "# test_solutions = pd.read_csv(test_solutions_path, sep=' ::: ', header=None, names=['ID', 'GENRE'], encoding='latin-1')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDkWSJ0FY51W"
      },
      "source": [
        "Cell 3: Preprocess the textual data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WOWYIVkY7HV"
      },
      "outputs": [],
      "source": [
        "# Preprocess the textual data\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "train_data['DESCRIPTION'] = train_data['DESCRIPTION'].apply(preprocess_text)\n",
        "test_data['DESCRIPTION'] = test_data['DESCRIPTION'].apply(preprocess_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew0H90Yhe3M7"
      },
      "source": [
        "Cell 4: Vectorize text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Adw0eLBEe3_I"
      },
      "outputs": [],
      "source": [
        "# Vectorize text data\n",
        "def vectorize_text(train_data, test_data, text_list):\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # Combine train, test, and additional text data for vectorization\n",
        "    combined_data = pd.concat([train_data['DESCRIPTION'], test_data['DESCRIPTION'], pd.Series(text_list)])\n",
        "\n",
        "    # Fit and transform TF-IDF vectorizer\n",
        "    X_tfidf = tfidf_vectorizer.fit_transform(combined_data)\n",
        "\n",
        "    # Split into train and test data\n",
        "    X_train_tfidf = X_tfidf[:len(train_data)]\n",
        "    X_test_tfidf = X_tfidf[len(train_data):(len(train_data) + len(test_data))]\n",
        "    X_text_list_tfidf = X_tfidf[(len(train_data) + len(test_data)):]\n",
        "\n",
        "    return X_train_tfidf, X_test_tfidf, X_text_list_tfidf, tfidf_vectorizer\n",
        "\n",
        "text_list = train_data['DESCRIPTION'].tolist()  # Text list used in the original preprocessing step\n",
        "X_train_tfidf, X_test_tfidf, X_text_list_tfidf, tfidf_vectorizer = vectorize_text(train_data, test_data, text_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au5MDfdDwUX4"
      },
      "source": [
        "Cell 5: Split data for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04dIxQIiwaNM"
      },
      "outputs": [],
      "source": [
        "# Split data for training and testing\n",
        "y_train = train_data['GENRE']\n",
        "y_test = test_solutions['GENRE']\n",
        "# Define genres\n",
        "genres = train_data['GENRE'].unique()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SPJ_Z79wgN4"
      },
      "source": [
        "Cell 6: Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY-jNmPFwhCR"
      },
      "outputs": [],
      "source": [
        "# Model training\n",
        "def train_models(X_train_tfidf, y_train):\n",
        "    nb_model = MultinomialNB()\n",
        "    nb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    lr_model = LogisticRegression(max_iter=1000)\n",
        "    lr_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    svm_model = SVC()\n",
        "    svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    return nb_model, lr_model, svm_model\n",
        "\n",
        "nb_model, lr_model, svm_model = train_models(X_train_tfidf, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQpeZSpkwy_t"
      },
      "source": [
        "Cell 7: Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-OJ1Hxcwz9O"
      },
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "def evaluate_models(model, X_test_tfidf, y_test, model_name):\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)\n",
        "    plt.xlabel('Predicted Genre')\n",
        "    plt.ylabel('Actual Genre')\n",
        "    plt.title(f'Confusion Matrix for {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "    # Save the confusion matrix as an image\n",
        "    plt.savefig(f'images/confusion_matrix_{model_name}.png')\n",
        "\n",
        "print(\"Evaluating Naive Bayes Model:\")\n",
        "evaluate_models(nb_model, X_test_tfidf, y_test, 'Naive Bayes')\n",
        "print(\"Evaluating Logistic Regression Model:\")\n",
        "evaluate_models(lr_model, X_test_tfidf, y_test, 'Logistic Regression')\n",
        "print(\"Evaluating Support Vector Machine Model:\")\n",
        "evaluate_models(svm_model, X_test_tfidf, y_test, 'SVM')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvpubZUnxCdB"
      },
      "source": [
        "Cell 8: Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLOIhERJxDZM"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning\n",
        "def tune_hyperparameters(model, param_grid, X_train_tfidf, y_train):\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train_tfidf, y_train)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "nb_param_grid = {'alpha': [0.1, 1.0, 10.0]}\n",
        "lr_param_grid = {'C': [0.1, 1.0, 10.0], 'max_iter': [100, 500, 1000]}\n",
        "svm_param_grid = {'C': [0.1, 1.0, 10.0], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
        "\n",
        "print(\"Tuning Naive Bayes Model:\")\n",
        "nb_model = tune_hyperparameters(nb_model, nb_param_grid, X_train_tfidf, y_train)\n",
        "print(\"Tuning Logistic Regression Model:\")\n",
        "lr_model = tune_hyperparameters(lr_model, lr_param_grid, X_train_tfidf, y_train)\n",
        "print(\"Tuning Support Vector Machine Model:\")\n",
        "svm_model = tune_hyperparameters(svm_model, svm_param_grid, X_train_tfidf, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm_a7S0rxIgh"
      },
      "source": [
        "Cell 9: Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmM4H_IUxK0H"
      },
      "outputs": [],
      "source": [
        "# Cross-validation\n",
        "def perform_cross_validation(model, X_train_tfidf, y_train):\n",
        "    cv_scores = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
        "    print(\"Cross-Validation Scores:\", cv_scores)\n",
        "    print(\"Mean CV Accuracy:\", np.mean(cv_scores))\n",
        "\n",
        "print(\"Cross-Validation for Naive Bayes Model:\")\n",
        "perform_cross_validation(nb_model, X_train_tfidf, y_train)\n",
        "print(\"Cross-Validation for Logistic Regression Model:\")\n",
        "perform_cross_validation(lr_model, X_train_tfidf, y_train)\n",
        "print(\"Cross-Validation for Support Vector Machine Model:\")\n",
        "perform_cross_validation(svm_model, X_train_tfidf, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r5_O3ZlxhCC"
      },
      "source": [
        "Cell 10: Train ensemble models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itWu64pdxikb"
      },
      "outputs": [],
      "source": [
        "# Train ensemble models\n",
        "def train_ensemble_models(X_train_tfidf, y_train):\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "    gb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    return rf_model, gb_model\n",
        "\n",
        "rf_model, gb_model = train_ensemble_models(X_train_tfidf, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngC_XJN2xmbf"
      },
      "source": [
        "Cell 11: Evaluate ensemble models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOMbteuPxnp_"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating Random Forest Model:\")\n",
        "evaluate_models(rf_model, X_test_tfidf, y_test, 'Random Forest')\n",
        "print(\"Evaluating Gradient Boosting Model:\")\n",
        "evaluate_models(gb_model, X_test_tfidf, y_test, 'Gradient Boosting')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtICLxUOxrpY"
      },
      "source": [
        "Cell 12: Visualize test predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Wz-TNmOxtRW"
      },
      "outputs": [],
      "source": [
        "# Visualize test predictions\n",
        "def visualize_test_predictions(model, X_test_tfidf, tfidf_vectorizer, genres):\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'Description': tfidf_vectorizer.inverse_transform(X_test_tfidf),\n",
        "        'Predicted Genre': y_pred,\n",
        "        'Actual Genre': y_test\n",
        "    })\n",
        "\n",
        "    # Select a sample for visualization\n",
        "    sample_predictions = predictions_df.sample(10)\n",
        "\n",
        "    for idx, row in sample_predictions.iterrows():\n",
        "        print(f\"Description: {' '.join(row['Description'])}\")\n",
        "        print(f\"Predicted Genre: {row['Predicted Genre']}\")\n",
        "        print(f\"Actual Genre: {row['Actual Genre']}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "    # Save the sample predictions as an image\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    table = ax.table(cellText=sample_predictions.values, colLabels=sample_predictions.columns, cellLoc='center', loc='center')\n",
        "    plt.savefig(f'images/sample_predictions_{model.__class__.__name__}.png')\n",
        "\n",
        "print(\"Visualizing Test Predictions for Naive Bayes Model:\")\n",
        "visualize_test_predictions(nb_model, X_test_tfidf, tfidf_vectorizer, genres)\n",
        "print(\"Visualizing Test Predictions for Logistic Regression Model:\")\n",
        "visualize_test_predictions(lr_model, X_test_tfidf, tfidf_vectorizer, genres)\n",
        "print(\"Visualizing Test Predictions for Support Vector Machine Model:\")\n",
        "visualize_test_predictions(svm_model, X_test_tfidf, tfidf_vectorizer, genres)\n",
        "print(\"Visualizing Test Predictions for Random Forest Model:\")\n",
        "visualize_test_predictions(rf_model, X_test_tfidf, tfidf_vectorizer, genres)\n",
        "print(\"Visualizing Test Predictions for Gradient Boosting Model:\")\n",
        "visualize_test_predictions(gb_model, X_test_tfidf, tfidf_vectorizer, genres)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_LhthS4xyS5"
      },
      "source": [
        "Cell 13: Save models and vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7UoGlcHxy4e"
      },
      "outputs": [],
      "source": [
        "# Save models and vectorizer\n",
        "def save_model(model, filename):\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump(model, file)\n",
        "\n",
        "save_model(nb_model, 'nb_model.pkl')\n",
        "save_model(lr_model, 'lr_model.pkl')\n",
        "save_model(svm_model, 'svm_model.pkl')\n",
        "save_model(rf_model, 'rf_model.pkl')\n",
        "save_model(gb_model, 'gb_model.pkl')\n",
        "save_model(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
